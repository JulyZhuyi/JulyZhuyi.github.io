<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>ARQ协议</title>
    <url>/2021/04/19/ARQ%E5%8D%8F%E8%AE%AE%E8%A7%A3%E6%9E%90/</url>
    <content><![CDATA[<h1 id="ARQ是什么"><a href="#ARQ是什么" class="headerlink" title="ARQ是什么"></a>ARQ是什么</h1><p>&nbsp; </p>
<p><strong>自动重传请求（Automatic Repeat reQuest），从名字看来，虽然被称为一种协议，但是看起来像是一种策略</strong></p>
<blockquote>
<p>ARQ，也可以是 Automatic Repeat Query 的缩写，是一种在数据传输时，使用确认（Acknoledgements，就是我们常说的ACK，接收方发送一个消息，告诉发送方，自己是否正确接到了一个包体）和超时（Timeouts，在收到一个确认消息之前，等待的一个确定的时间段）机制，在不可靠的网络上，实现可靠的数据传输的错误控制方法。如果发送方在超时之前没有收到确认，通常会重新传输相应的包体，直到收到确认或者重试超过一定的次数。<br><strong><a href="https://en.wikipedia.org/wiki/Automatic_repeat_request">维基百科</a></strong></p>
</blockquote>
<p>&nbsp; </p>
<h1 id="常见策略"><a href="#常见策略" class="headerlink" title="常见策略"></a>常见策略</h1><h2 id="停止等待ARQ（Stop-amp-Wait）"><a href="#停止等待ARQ（Stop-amp-Wait）" class="headerlink" title="停止等待ARQ（Stop &amp; Wait）"></a>停止等待ARQ（Stop &amp; Wait）</h2><p>最为原始的一种ARQ实现方式。如下图：   </p>
<ul>
<li>发送方发送一帧后，必须等待接收方确认（ACK）才能发送下一帧。  </li>
<li>发送方发送完一个帧后，就会设置一个超时计时器，如果超时计时器到期之前没有收到接收方发来的确认信息，则会重发刚发送过的分组；如果收到确认信息，则撤销该超时计时器。<br><img src="stop.jpg" alt="stop and wait">  </li>
</ul>
<h2 id="连续ARQ"><a href="#连续ARQ" class="headerlink" title="连续ARQ"></a>连续ARQ</h2><p>连续ARQ通常是结合滑动窗口协议来使用的，发送方需要维持一个发送窗口，如下图所示：<br><img src="seq-arq.jpg" alt="stop and wait"><br>图(a)是发送方维持的一个发送窗口，它的意义在于，位于发送窗口的5个分组都可以连续发送出去，而不需要等待对方的确认，这样大大提高了信道的利用率。<br>连续ARQ协议规定，发送方每收到一个确认，就把发送窗口向前滑动一个分组的位置。例如上面的图（b），当发送方收到第一个分组的确认，就把发送窗口向前移动一个分组的位置。如果原来已经发送了前5个分组，则现在可以发送窗口内的第6个分组。  </p>
<p><strong>若发送过程中出现错误，连续ARQ采用的两种方式如下：</strong><br><strong>- 回退N帧（GO back N)</strong>  </p>
<ul>
<li>接受点丢弃从第一个没有收到的数据包开始的所有数据包</li>
<li>发送点收到NACK后，从NACK中指明的数据包开始重新发送  </li>
</ul>
<p><strong>- 选择性重传（Selective Repeat）</strong>  </p>
<ul>
<li>发送点连续发送数据包但对每个数据包都设有一个计时器</li>
<li>当在一定时间内没有收到某个数据包的ACK时，发送点只发送那个没有ACK的数据包<br>&nbsp;    </li>
</ul>
<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><p>&nbsp;<br>ARQ是一种在数据传输过程中，错误控制的策略，保证了数据的完整性和有序性。核心目的是在不可靠的网络上实现可靠的传输。比如，无线通信中在WCDMA和cdma2000无线通信中都采用了选择性重传ARQ和混合ARQ。       </p>
<p>在服务端开发方面，ARQ的思想给我们很多的启发。此外，这种策略的学习和理解，是我们理解更复杂的网络协议的基础。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title>mysql binlog</title>
    <url>/2021/04/27/Mysql-binlog/</url>
    <content><![CDATA[<h1 id="Binlog是什么"><a href="#Binlog是什么" class="headerlink" title="Binlog是什么"></a>Binlog是什么</h1><p>二进制日志，用于记录数据库的写入性操作信息，以二进制的方式保存在磁盘。是Mysql的逻辑日志，并且由Server层进行记录，与存储引擎无关。<br>&nbsp; </p>
<h1 id="Binlog的使用场景"><a href="#Binlog的使用场景" class="headerlink" title="Binlog的使用场景"></a>Binlog的使用场景</h1><p>   主从复制：在Master端开启binlog，然后将binlog日志发送到各个Slave端，由Slave端重放Binlog最终达到主从一致<br>   数据恢复：通过使用mysqlbinlog工具来恢复数据<br>&nbsp;<br>&nbsp;    </p>
<h1 id="Binlog日志格式"><a href="#Binlog日志格式" class="headerlink" title="Binlog日志格式"></a>Binlog日志格式</h1><p><code>show variables like &#39;binlog_format&#39; //查看binlog日志格式</code></p>
<h2 id="statement"><a href="#statement" class="headerlink" title="statement"></a>statement</h2><p>   <strong>语句模式 – 基于sql语句的复制，每一条会修改数据的sql语句会记录到binlog里</strong><br>    <strong>优点</strong>：不需要记录每行的变化，减少了Binlog日志量，节约了IO，提高性能<br>    <strong>缺点</strong>：由于记录的只是执行语句，为了这些语句能在Slave上正确运行， 因此还必须记录每条语句在执行的时候的一些相关信息，以保证所有语句在Slave得到和在Master端执行时候相同的结果。另外Mysql的复制，像一些特定函数功能，Slave可与Master保持一致会有很多相关问题。</p>
<h2 id="row"><a href="#row" class="headerlink" title="row"></a>row</h2><p>   <strong>行模式 – 基于行的复制，不记录sql语句的上下文，只记录哪条记录被修改</strong><br>   <strong>优点</strong>：不会出现某些特定情况下的存储过程，或function，以及trigger的调用和触发无法被正确复制的问题<br>   <strong>缺点</strong>：需要记录每行记录的修改，可能会产生大量的日志内容<br>   注：新版本的MySQL对row模式做了优化，并不是所有的修改都会以row来记录，比如遇到表结构变更的时候会以statement模式来记录，如果遇到update或者delete等修改语句，还是会记录所有行的变更</p>
<h2 id="mixed"><a href="#mixed" class="headerlink" title="mixed"></a>mixed</h2><p>   <strong>混合模式</strong>  <em><strong><a href="https://dev.mysql.com/doc/refman/5.7/en/binary-log-mixed.html">官方文档</a></strong></em><br>   5.1.8版本开始，提供mixed格式，即statement与row的混合模式，在一些特定环境下会自动切换。比如，以下情况mixed会转换成row模式<br>    <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">当 DML 语句更新一个 NDB 表时；  </span><br><span class="line">当函数中包含 UUID() 时；    </span><br><span class="line">2 个及以上包含 AUTO_INCREMENT 字段的表被更新时；    </span><br><span class="line">执行 INSERT DELAYED 语句时；    </span><br><span class="line">用 UDF 时；     </span><br><span class="line">视图中必须要求运用 row 时，例如建立视图时使用了 UUID() 函数；</span><br></pre></td></tr></table></figure><br>&nbsp;</p>
<h1 id="Binlog刷盘时机"><a href="#Binlog刷盘时机" class="headerlink" title="Binlog刷盘时机"></a>Binlog刷盘时机</h1><p>   <strong>sync_binlog参数 — 同步binlog，持久化到硬盘，取值0，1，N</strong><br>   <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">0:  不去强制要求，由系统判断刷盘时机  </span><br><span class="line">1:  每次commit的时候将binlog写入磁盘   </span><br><span class="line">N:  每N个事务才会将Binlog写入磁盘</span><br></pre></td></tr></table></figure></p>
<pre><code>show variables like &#39;sync_binlog&#39;; //查看参数设置
set global sync_binlog=0; //设置sync_binlog参数值
</code></pre>
<p>&nbsp;</p>
<h1 id="Binlog其他相关语句"><a href="#Binlog其他相关语句" class="headerlink" title="Binlog其他相关语句"></a>Binlog其他相关语句</h1><pre><code>show variables like &#39;log_bin&#39;;  //查看是否开启binlog日志
show variables like &#39;binlog_format&#39;; //查看binlog日志格式
show global variables like &#39;%log%&#39;; //查看binlog所在目录
show binary logs;  //查看当前服务器使用的binlog文件及大小
show binlog events in &#39;binlog.000017&#39;; //查看具体一个binlog文件的内容
</code></pre>
<p>&nbsp;</p>
<h1 id="mysqlbinlog命令的使用及说明"><a href="#mysqlbinlog命令的使用及说明" class="headerlink" title="mysqlbinlog命令的使用及说明"></a>mysqlbinlog命令的使用及说明</h1><p>   其命令可以使binlog日志以文本的方式显示，如下图<br>    <img src="mysqlbinlog.png" alt="mysqlbinlog"><br>    图片中日志的说明如下：<br>        <figure class="highlight plain"><table><tr><td class="code"><pre><span class="line">position：位于文件中的位置，说明该事件记录从文件第210306个字节开始  &#x2F;&#x2F;#210306       </span><br><span class="line">timestamp：事件发生的时间戳 &#x2F;&#x2F;22:25:42   </span><br><span class="line">server id：服务器标识   </span><br><span class="line">end_log_pos：表示下一个事件开始的位置     </span><br><span class="line">thread_id：执行该事件的线程ID     </span><br><span class="line">exec_time：时间执行花费的时间      </span><br><span class="line">error_code：错误码，0意味着没有发生错误    </span><br><span class="line">type：事件类型Query </span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>binlog</tag>
        <tag>mysql日志</tag>
      </tags>
  </entry>
  <entry>
    <title>redis五种数据结构-String</title>
    <url>/2021/05/23/redis%E4%BA%94%E7%A7%8D%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84-String/</url>
    <content><![CDATA[<h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>Redis自定义了字符串类型(SDS，全称Simple Dynamic Strings)。<br>typedef char *sds;</p>
<h1 id="二、SDS详解"><a href="#二、SDS详解" class="headerlink" title="二、SDS详解"></a>二、SDS详解</h1><h2 id="sds-header结构定义"><a href="#sds-header结构定义" class="headerlink" title="sds header结构定义"></a>sds header结构定义</h2><pre><code>/* Note: sdshdr5 is never used, we just access the flags byte directly.* However is here to document the layout of type 5 SDS strings. */  

struct __attribute__ ((__packed__)) sdshdr5 &#123;
unsigned char flags; /* 3 lsb of type, and 5 msb of string length */
char buf[];
&#125;;  

struct __attribute__ ((__packed__)) sdshdr8 &#123;
uint8_t len; /* used */
uint8_t alloc; /* excluding the header and null terminator */
unsigned char flags; /* 3 lsb of type, 5 unused bits */
char buf[];
&#125;;  

struct __attribute__ ((__packed__)) sdshdr16 &#123;
uint16_t len; /* used */
uint16_t alloc; /* excluding the header and null terminator */
unsigned char flags; /* 3 lsb of type, 5 unused bits */
char buf[];
&#125;;  

struct __attribute__ ((__packed__)) sdshdr32 &#123;
uint32_t len; /* used */
uint32_t alloc; /* excluding the header and null terminator */
unsigned char flags; /* 3 lsb of type, 5 unused bits */
char buf[];
&#125;;  

struct __attribute__ ((__packed__)) sdshdr64 &#123;
uint64_t len; /* used */
uint64_t alloc; /* excluding the header and null terminator */
unsigned char flags; /* 3 lsb of type, 5 unused bits */
char buf[];
&#125;;  
</code></pre>
<p>sds 采用一段连续的内存空间来存储动态字符串，即 header + str 的形式。<strong>attribute</strong> ((packed))是为了让编译器使用紧凑模式来分配内存，不对struct中的字段进行内存对齐，以此保证 header 和 sds 的数据部分紧紧的相邻，否则，不能按照固定的偏移来获取 flags 字段。<br>当定义了 sds* s 后，使用 s[-1] 就可以获得 flag 的值，这样就知道了这个 sds 属于哪种类型。</p>
<h2 id="sds-header结构详解"><a href="#sds-header结构详解" class="headerlink" title="sds header结构详解"></a>sds header结构详解</h2><p>len: 字符串真正的长度（不包含NULL结束符在内）<br>alloc: 字符串的最大容量<br>flags: 总是包含一个字节，其中低三位表示header的类型<br>sdshdr5与其他几个header结构不同，不包含len和alloc。sdshdr5长度使用flags的高五位来存储。因此，它不能为字符串分配额外的空间，如果字符串要动态增长，那么它就必然要重新分配内存才行。所以，sdshdr5更适合存储静态的短字符串（长度小于32）。    </p>
<h2 id="sds-header优点"><a href="#sds-header优点" class="headerlink" title="sds header优点"></a>sds header优点</h2><p>sds header其实隐藏在真正字符串的数据前面，这样一个定义，有如下好处：<br>a.hheader和数据相邻，而不用分成两块内存空间来单独分配。这有利于减少内存碎片，提高存储效率（memory efficiency）。<br>b.虽然header有多个类型，但sds可以用统一的char *来表达。且它与传统的C语言字符串保持类型兼容。  </p>
<h2 id="SDS数组动态分配策略"><a href="#SDS数组动态分配策略" class="headerlink" title="SDS数组动态分配策略"></a>SDS数组动态分配策略</h2><h3 id="空间预分配"><a href="#空间预分配" class="headerlink" title="空间预分配"></a>空间预分配</h3><ul>
<li>当SDS的len属性长度小于1MB时，redis会分配和len相同长度的free空间。   </li>
<li>当SDS的len属性长度大于1MB时，程序将多分配1M的未使用空间。</li>
</ul>
<h3 id="惰性空间"><a href="#惰性空间" class="headerlink" title="惰性空间"></a>惰性空间</h3><p>redis的内存回收采用惰性回收，字符串变短不会立即交还操作系统，先留着以便之后马上要使用。短暂的持有资源，既可以充分利用资源，也可以不浪费资源。   </p>
<h2 id="SDS的特点"><a href="#SDS的特点" class="headerlink" title="SDS的特点"></a>SDS的特点</h2><ul>
<li>二进制安全（Binary Safe），sds能存储任意二进制数据  </li>
<li>与传统的C语言字符串类型兼容   </li>
<li>预分配空间，可以懒惰释放，在内存紧张的时候也可以缩减不需要的内存  </li>
<li>常数复杂度获取字符串长度    </li>
<li>杜绝缓冲区溢出，边界检查</li>
</ul>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redis数据结构</tag>
      </tags>
  </entry>
  <entry>
    <title>RedisCluster原理</title>
    <url>/2021/05/17/RedisCluster%E5%8E%9F%E7%90%86/</url>
    <content><![CDATA[<h1 id="一、背景"><a href="#一、背景" class="headerlink" title="一、背景"></a>一、背景</h1><p>主从复制需人工介入，不能自动化完成，即不能达到高可用<br>业务需要更高的QPS，而主从复制中单机的QPS可能无法满足业务需求</p>
<h1 id="二、基本原理"><a href="#二、基本原理" class="headerlink" title="二、基本原理"></a>二、基本原理</h1><h2 id="1、基本架构"><a href="#1、基本架构" class="headerlink" title="1、基本架构"></a>1、基本架构</h2><p>Redis Cluster中有多个节点，每个节点都负责进行数据读写操作，每个节点之间会进行通信。<br><img src="framework.png" alt="framework">  </p>
<h3 id="结点状态信息结构"><a href="#结点状态信息结构" class="headerlink" title="结点状态信息结构"></a>结点状态信息结构</h3><p>Cluster中的每个节点节点通过Gossip协议传播信息，都维护一份当前整个集群的状态，状态信息主要包括：<br>    a. 当前集群状态<br>    b. 集群中各节点所负责的slots信息，及其migrate状态<br>    c. 集群中各节Gossip协议点的master-slave状态<br>    d. 集群中各节点的存活状态及不可达投票  </p>
<h3 id="Gossip协议介绍"><a href="#Gossip协议介绍" class="headerlink" title="Gossip协议介绍"></a>Gossip协议介绍</h3><h4 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h4><blockquote>
<p>gossip 协议（gossip protocol）又称 epidemic 协议（epidemic protocol），是基于流行病传播方式的节点或者进程之间信息交换的协议。<br>在分布式系统中被广泛使用，比如我们可以使用 gossip 协议来确保网络中所有节点的数据一样。<br>gossip protocol 最初是由施乐公司帕洛阿尔托研究中心（Palo Alto Research Center）的研究员艾伦·德默斯（Alan Demers）于1987年创造的。          </p>
</blockquote>
<h4 id="执行过程"><a href="#执行过程" class="headerlink" title="执行过程"></a>执行过程</h4><p>是由种子节点发起，当一个种子节点有状态需要更新到网络中的其他节点时，它会随机的选择周围几个节点散播消息，收到消息的节点也会重复该过程，直至最终网络中所有的节点都收到了消息。这个过程可能需要一定的时间，由于不能保证某个时刻所有节点都收到消息，但是理论上最终所有节点都会收到消息，因此它是一个最终一致性协议。</p>
<h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><h5 id="消息的延迟"><a href="#消息的延迟" class="headerlink" title="消息的延迟"></a>消息的延迟</h5><p>由于 Gossip 协议中，节点只会随机向少数几个节点发送消息，消息最终是通过多个轮次的散播而到达全网的，因此使用 Gossip 协议会造成不可避免的消息延迟。不适合用在对实时性要求较高的场景下。</p>
<h5 id="消息冗余"><a href="#消息冗余" class="headerlink" title="消息冗余"></a>消息冗余</h5><p>Gossip 协议规定，节点会定期随机选择周围节点发送消息，而收到消息的节点也会重复该步骤，因此就不可避免的存在消息重复发送给同一节点的情况，造成了消息的冗余，同时也增加了收到消息的节点的处理压力。而且，由于是定期发送，因此，即使收到了消息的节点还会反复收到重复消息，加重了消息的冗余。</p>
<h5 id="拜占庭问题"><a href="#拜占庭问题" class="headerlink" title="拜占庭问题"></a>拜占庭问题</h5><p>即如果有一个恶意传播消息的节点，gossip协议的分布式系统就会出问题<br>&nbsp; </p>
<h2 id="2、数据分片"><a href="#2、数据分片" class="headerlink" title="2、数据分片"></a>2、数据分片</h2><p>采用虚拟槽分区的方式。RedisCluster中有一个16384长度的槽，他们的编号为0、1、2、3……16382、16383。这个槽是一个虚拟的槽，并不是真正存在的。正常工作的时候，Redis Cluster中的每个Master节点都会负责一部分的槽，当有某个key被映射到某个Master负责的槽，那么这个Master负责为这个key提供服务，至于哪个Master节点负责哪个槽，这是可以由用户指定的，也可以在初始化的时候自动生成（redis-trib.rb脚本）。在Redis Cluster中，只有Master才拥有槽的所有权，如果是某个Master的slave，这个slave只负责槽的使用，但是没有所有权。具体步骤如下：<br>（1）把16384槽按照节点数量进行平均分配，由节点进行管理<br>（2）对每个key按照CRC16规则进行hash运算<br>（3）把hash结果对16383进行取余<br>（4）把余数发送给Redis节点<br>（5）节点接收到数据，验证是否在自己管理的槽编号的范围<br>    如果在自己管理的槽编号范围内，则把数据保存到数据槽中，然后返回执行结果<br>    如果在自己管理的槽编号范围外，则会把数据发送给正确的节点，由正确的节点来把数据保存在对应的槽中</p>
<h2 id="3、节点的槽指派信息"><a href="#3、节点的槽指派信息" class="headerlink" title="3、节点的槽指派信息"></a>3、节点的槽指派信息</h2><p>clusterNode结构记录了节点负责处理那些槽：<br>struct clusterNode {<br>//…<br>unsignedchar slots[16384/8];<br>};<br>slots属性是一个二进制位数组(bit array)，数组的长度为16384/8=2048个字节，共包含16384个二进制位。<br>Master节点用bit来标识对于某个槽自己是否拥有。比如对于编号为1的槽，Master只要判断slots[1]是否为1，时间复杂度为O（1）。</p>
<h2 id="4、集群所有槽的指派信息"><a href="#4、集群所有槽的指派信息" class="headerlink" title="4、集群所有槽的指派信息"></a>4、集群所有槽的指派信息</h2><p>将所有槽的指派信息保存在clusterState.slots数组里，若要检查槽i是否已被指派，只需访问clusterState.slots[i]的值即可，复杂度仅为O（1）。</p>
<h2 id="5、请求重定向"><a href="#5、请求重定向" class="headerlink" title="5、请求重定向"></a>5、请求重定向</h2><p>由于每个节点只负责部分slot，并且slot也可能从一个节点迁移到另一节点，造成客户端有可能会向错误的节点发起请求。因此需要有一种机制来对其进行发现和修正，这就是请求重定向。有两种不同的重定向场景：</p>
<h3 id="MOVED"><a href="#MOVED" class="headerlink" title="MOVED"></a>MOVED</h3><pre><code>a.客户端向Redis Cluster的任意节点发送命令，接收命令的节点会根据CRC16规则进行hash运算与16383取余，计算自己的槽和对应节点
b.若请求的key对应的槽不在自己的节点上，将查看自身内部所保存的哈希槽到节点ID的映射记录，则向客户端返回moved重定向异常。
c.客户端接收到节点返回的结果，如果是moved异常，则从moved异常中获取目标节点的信息
d.客户端向目标节点发送命令，获取命令执行结果
</code></pre>
<h3 id="ASK"><a href="#ASK" class="headerlink" title="ASK"></a>ASK</h3><pre><code>a.客户端向目标节点发送命令，目标节点中的槽已经迁移支别的节点上了，此时目标节点会返回ask转向给客户端
b.客户端向新的节点发送Asking命令给新的节点，然后再次向新节点发送命令
c.新节点执行命令，把命令执行结果返回给客户端
</code></pre>
<p>在对集群进行扩容和缩容时，需要对槽及槽中数据进行迁移，当客户端向某个节点发送命令，节点向客户端返回moved异常，告诉客户端数据对应的槽的节点信息。如果此时正在进行集群扩展或者缩空操作，当客户端向正确的节点发送命令时，槽及槽中数据已经被迁移到别的节点了，就会返回ask，这就是ask重定向机制。 </p>
<h2 id="6、数据迁移"><a href="#6、数据迁移" class="headerlink" title="6、数据迁移"></a>6、数据迁移</h2><p>当 槽X 从NodeA向NodeB迁移时，NodeA和NodeB都会有这个槽X，NodeA上槽X的状态设置为MIGRATING，NodeB上槽X的状态被设置为IMPORTING。<br><img src="cluster.jpg" alt="cluster data">  </p>
<h2 id="7、故障发现"><a href="#7、故障发现" class="headerlink" title="7、故障发现"></a>7、故障发现</h2><p>Redis Cluster通过ping/pong消息实现故障发现，不需要sentinel<br>ping/pong不仅能传递节点与槽的对应消息，也能传递其他状态，比如：节点主从状态，节点故障等<br>分为主观下线和客观下线</p>
<h3 id="主观下线"><a href="#主观下线" class="headerlink" title="主观下线"></a>主观下线</h3><pre><code>a.节点1定期发送ping消息给节点2
b.如果发送成功，代表节点2正常运行，节点2会响应PONG消息给节点1，节点1更新与节点2的最后通信时间
c.如果发送失败，则节点1与节点2之间的通信异常判断连接，在下一个定时任务周期时，仍然会与节点2发送ping消息
d.如果节点1发现与节点2最后通信时间超过node-timeout，则把节点2标识为pfail状态
</code></pre>
<h3 id="客观下线"><a href="#客观下线" class="headerlink" title="客观下线"></a>客观下线</h3><pre><code>a.某个节点接收到其他节点发送的ping消息，如果接收到的ping消息中包含了其他pfail节点，这个节点会将主观下线的消息内容添加到自身的故障列表中，故障列表中包含了当前节点接收到的每一个节点对其他节点的状态信息
b.当前节点把主观下线的消息内容添加到自身的故障列表之后，会尝试对故障节点进行客观下线操作
</code></pre>
<h2 id="8、故障转移"><a href="#8、故障转移" class="headerlink" title="8、故障转移"></a>8、故障转移</h2><pre><code>a.偏移量最大的从节点具备优先级成为主节点的条件
b.对选举出来的多个从节点进行投票，选出新的主节点
c.当前从节点变成主节点(slaveof no one)，执行cluster del slot撤销故障主节点负责的槽，并执行cluster add slot把这些槽分配给自己
d.向集群广播自己的pong消息，表明已经替换了故障从节点
</code></pre>
<h1 id="三、RedisCluster的缺点"><a href="#三、RedisCluster的缺点" class="headerlink" title="三、RedisCluster的缺点"></a>三、RedisCluster的缺点</h1><p><strong>缺点：</strong>当节点数量很多时，性能不会很高<br><strong>解决：</strong>使用智能客户端。智能客户端知道由哪个节点负责管理哪个槽，而且当节点与槽的映射关系发生改变时，客户端也会知道这个改变，这是一种非常高效的方式</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redis高可用</tag>
        <tag>redis cluster</tag>
      </tags>
  </entry>
  <entry>
    <title>redis哨兵机制</title>
    <url>/2021/05/13/redis%E5%93%A8%E5%85%B5%E6%9C%BA%E5%88%B6/</url>
    <content><![CDATA[<h1 id="一、主从复制的问题"><a href="#一、主从复制的问题" class="headerlink" title="一、主从复制的问题"></a>一、主从复制的问题</h1><p>redis主从复制有个缺点，当主机master宕机以后，我们需要人工解决切换，比如使用slaveof on one。主从复制并没事实现高可用，高可用需要在某台机器发生故障之后，其他后备的机器可以迅速的接替并提供服务。</p>
<h1 id="二、如何解决"><a href="#二、如何解决" class="headerlink" title="二、如何解决"></a>二、如何解决</h1><p>如果我们有一个监控程序能够监控各个机器的状态，并及时调整，将手动操作变成自动的。Sentinel就是解决此问题的。</p>
<h1 id="三、哨兵机制的原理"><a href="#三、哨兵机制的原理" class="headerlink" title="三、哨兵机制的原理"></a>三、哨兵机制的原理</h1><p>Redis Sentinel一个分布式架构，其中包含若干个Sentinel节点和Redis数据节点，每个Sentinel节点会对Redis数据节点以及其他的Sentinel节点进行监控，如果发现节点不可达时，会对节点做下线标识。<br>如果被标识的是主节点，它还会和其他Sentinel节点进行“协商”。当大多数Sentinel认为主节点不可达时，它们会选举出一个Sentinel节点进行故障转移的工作，同时会将整个变化通知Redis应用方。整个过程是自动的，不需要人工介入，所以有效的解决了Redis高可用的问题。<br><img src="framework.jpg" alt="framework"> </p>
<h1 id="四、Sentinel包含的功能"><a href="#四、Sentinel包含的功能" class="headerlink" title="四、Sentinel包含的功能"></a>四、Sentinel包含的功能</h1><p>监控：Sentinel会定期检查Redis数据节点，以及其他Sentinel节点是否可达<br>通知：Sentinel会将故障转移的结果通知给应用方<br>主节点故障转移：实现从节点晋升主节点并维护后续正确的主从关系<br>充当配置中心：如果发生故障转移，会通知将master的新地址写在配置中心告诉客户端<br>&nbsp; </p>
<h1 id="五、Sentinel实现原理"><a href="#五、Sentinel实现原理" class="headerlink" title="五、Sentinel实现原理"></a>五、Sentinel实现原理</h1><h3 id="1、检测问题"><a href="#1、检测问题" class="headerlink" title="1、检测问题"></a>1、检测问题</h3><p>– 主要是三个定时任务<br>每隔10秒， 每个Sentinel节点会向主节点和从节点发送info命令获取最新的拓扑结构。<br>每隔2秒， 每个Sentinel节点会向Redis数据节点的__sentinel__： hello 频道上发送该Sentinel节点对于主节点的判断以及当前Sentinel节点的信息， 同时每个Sentinel节点也会订阅该频道， 来了解其他Sentinel节点以及它们对主节点的判断。<br>每隔1秒， 每个Sentinel节点会向主节点、 从节点、 其余Sentinel节点发送一条ping命令做一次心跳检测， 来确认这些节点当前是否可达。  </p>
<h3 id="2、发现问题"><a href="#2、发现问题" class="headerlink" title="2、发现问题"></a>2、发现问题</h3><p><strong>主要讲的是客观下线和主关下线。如果Sentinel机器发现问题，就会对它主观下线。当多个Sentinel都发现有问题的时候，才会进行客观下线。</strong><br>sdown，即主观宕机，如果一个哨兵它自己觉得master宕机了，就是主观宕机<br>odown，即客观宕机，如果quorum数量的哨兵都认为一个master宕机了，则为客观宕机<br>哨兵在ping一个master的时候，如果超过了is-master-down-after-milliseconds指定的毫秒数之后，就是达到了sdown，就主观认为master宕机了。<br>如果一个哨兵在指定时间内，收到了quorum指定数量的其他哨兵也认为那个master是sdown了，那么就认为是odown了，客观认为master宕机，就完成了sdown到odown的转换。</p>
<h3 id="3、解决问题-领导者选举"><a href="#3、解决问题-领导者选举" class="headerlink" title="3、解决问题-领导者选举"></a>3、解决问题-领导者选举</h3><p><strong>如果一个master被认为odown了，而且majority哨兵都允许了主备切换，那么某个哨兵就会执行主备切换操作，此时首先要选举一个slave来，主要通过下面几个步骤：</strong><br>按照slave优先级进行排序，slave priority越低，优先级就越高。<br>如果slave priority相同，那么看replica offset，哪个slave复制了越多的数据，offset越靠后，优先级就越高。<br>如果上面两个条件都相同，那么选择一个run id比较小的那个slave</p>
<h3 id="4、解决问题-故障转移"><a href="#4、解决问题-故障转移" class="headerlink" title="4、解决问题-故障转移"></a>4、解决问题-故障转移</h3><p>a. 领导者sentinel从slave中选一台，对这个slave执行slaveof no one 让其成为master。<br>b. 向剩余的slave发送命令，执行slaveof 让其成为新master的slave节点。此时新master不会对slave进行全量复制（这个通过查看新master和slave的日志文件看到确实没有进行全量复制，而是Trying a partial resynchronization  …即部分复制），而是进行一个部分复制（如果偏移量不超出新master的复制积压缓冲区的话）<br>c. 故障转移后，sentinel会关注原master，如果原master重启，sentinel会将让其同步新master，它自己就变成了slave。此时master会对这个重启的slave进行全量复制。<br>&nbsp; </p>
<h1 id="六、哨兵常见问题与解决方法"><a href="#六、哨兵常见问题与解决方法" class="headerlink" title="六、哨兵常见问题与解决方法"></a>六、哨兵常见问题与解决方法</h1><p><strong>哨兵在发现master node挂掉之后，其中一个slave node会提升为master node。在这过程中，可能会发生数据丢失。</strong></p>
<h2 id="主从异步导致的数据丢失"><a href="#主从异步导致的数据丢失" class="headerlink" title="主从异步导致的数据丢失"></a>主从异步导致的数据丢失</h2><p><strong>问题：</strong>因为master-&gt;slave的复制是异步的，有可能部分没有来得及复制master就宕机了<br><strong>解决：</strong>配置min-slaves-max-lag=10（ 数据复制和同步的延迟不能超过10S），当我们的slave在数据复制的时候，发现返回的ACK时延太长达到了 min-slaves-max-lag 配置，这个时候就会认为如果master宕机就会导致大量数据丢失，提前进行了预测，就不再去接收客户端的任何请求了，来将丢失的数据降低在可控范围内。<br><img src="sovle.jpg" alt="solve"> </p>
<h2 id="脑裂导致的数据丢失"><a href="#脑裂导致的数据丢失" class="headerlink" title="脑裂导致的数据丢失"></a>脑裂导致的数据丢失</h2><p><strong>问题：</strong>所谓的脑裂，就是指在主从集群中，同时有两个主节点，它们都能接收写请求。而脑裂最直接的影响，就是客户端不知道应该往哪个主节点写入数据，结果就是不同的客户端会往不同的主节点上写入数据。而且，严重的话，脑裂会进一步导致数据丢失。<br><strong>解决：</strong>设置min-slaves-to-write（主库连接的从库中 至少有 N 个从库）、min-slaves-max-lag=10（ 数据复制和同步的延迟不能超过10S） 如果master出现了脑裂与其他的slave失去了通信，master不能给指定数量的salve发送数据，slave超过10S没有给自己返回ack消息，master就会拒接客户端的写入。</p>
]]></content>
      <categories>
        <category>技术</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>redis高可用</tag>
        <tag>redis哨兵机制</tag>
      </tags>
  </entry>
  <entry>
    <title>relay-log和主从复制</title>
    <url>/2021/04/28/relay-log%E5%92%8C%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6/</url>
    <content><![CDATA[]]></content>
      <categories>
        <category>技术</category>
      </categories>
  </entry>
</search>
